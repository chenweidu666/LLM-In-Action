# 写作 Agent — 基于网文语料的风格化创作助手

> 构思日期：2026-02-09
> 状态：规划中

## 灵感来源

手上有两类独特的数据资产：

1. **中文网文语料**：45 部完结小说（~30 万行），以电竞/网配/甜宠题材为主
2. **日本电影中日双语字幕**：NAS 上 51 个系列、104+ 部电影的 `.ja-zh.srt`（正在通过 faster-whisper + Qwen API 自动生成）

结合现有的 LLM 基础设施（Qwen 模型、LORA 训练、RAG 管线、Agent 框架），可以构建一个有实际价值的写作 Agent。

---

## 数据资产

### 中文网文（45 部，~30 万行）

```
路径: ~/Desktop/3_Fullstack_Projects/4_LLM_Project/0_Datastes/backup/TX_Others/
题材: 电竞、网配、声控、甜宠言情
代表作: 蜜汁炖鱿鱼(墨宝非宝)、密室困游鱼、大神你外挂呢、诺森德(网游)
```

特点：
- 对白密集，适合学习角色互动和情感表达
- 题材集中（电竞+恋爱），风格一致性好
- 叙事节奏成熟，可学习章节结构

### 中日双语字幕（持续生成中）

```
来源: NAS /volume2/Movies/学术研究/日本电影/
格式: .ja-zh.srt（日文在上，中文在下，带时间戳）
```

特点：
- 真实影视对白，口语化强
- 中日对照，可用于翻译风格学习
- 场景化语境丰富

---

## 可行方案

### 方案 A：RAG 写作助手（快速原型，1-2 天）

**思路**：不训练模型，用 RAG 检索网文片段作为风格参考，Qwen API 生成。

```
用户输入大纲/设定 → 检索相似风格段落 → Qwen 参考风格生成 → 输出章节
```

**技术栈**：
- 向量库：Chroma（已有 `5_RAG/` 基础代码）
- Embedding：bge-large-zh-v1.5
- 生成：Qwen-Plus API（DashScope）
- 界面：Gradio（已有 `2_Agent/MyAgent/gradio_v3.py`）

**优点**：零训练成本、快速验证、API 模型质量高
**缺点**：风格模仿深度有限、依赖 API 费用

### 方案 B：LORA 微调（更好效果，3-5 天）

**思路**：将网文转换为训练数据，LORA 微调 Qwen3 模型，让模型内化写作风格。

```
网文 → 提取 (上文, 续写) 对 → LORA 微调 Qwen3-0.6B → 本地部署
```

**数据准备**：
- 章节级：给定前 N 段，生成下一段
- 对白级：给定场景描述，生成角色对白
- 风格级：给定普通文本，改写为特定风格

**技术栈**：
- 模型：Qwen3-0.6B（已通过 ModelScope 下载，`0_download.py`）
- 微调：LORA（已有 `4_LORA/` 代码）
- 训练：RTX 3060 12GB（ubuntu-3060）

**优点**：风格模仿更自然、无 API 费用、可离线运行
**缺点**：需要数据清洗 + 训练时间、小模型上限有限

### 方案 C：Agent 编排（完整体验）

**思路**：构建多步骤写作 Agent，编排完整创作流程。

```
Step 1: 规划（大纲生成 + 角色设定）
Step 2: 展开（逐章节生成，RAG 检索保持风格一致）
Step 3: 润色（对白优化、情感渲染、前后一致性检查）
Step 4: 审校（逻辑检查、角色性格一致性）
```

**技术栈**：
- Agent 框架：OpenManus（已有 `2_Agent/OpenManus/`）或自建
- RAG：风格检索 + 上下文记忆
- LLM：LORA 微调模型 + Qwen API（混合使用）

---

## 扩展方向

### 日语学习应用（利用双语字幕）

- **影视日语对话库**：按场景分类（日常/恋爱/职场），检索真实用例
- **听力练习生成**：音频片段 + 填空/翻译练习
- **RAG 日语问答**："这个场景日语怎么说" → 从字幕库检索

### 跨媒体工具

- **小说→剧本转换**：网文章节 → 分镜剧本格式
- **角色对白生成器**：融合网文 + 影视对白风格

---

## 实施优先级

| 优先级 | 方案 | 预计耗时 | 依赖 |
|--------|------|----------|------|
| P0 | 方案 A: RAG 写作助手 | 1-2 天 | Qwen API + Chroma |
| P1 | 方案 B: LORA 微调 | 3-5 天 | 3060 GPU + 数据清洗 |
| P2 | 方案 C: Agent 编排 | 1-2 周 | A/B 完成后 |
| P3 | 日语学习应用 | 1 周 | 双语字幕生成完成后 |

## 现有可复用代码

```
4_LLM_Project/
├── 0_Datastes/backup/TX_Others/  # 45 部网文语料
├── 0_Datastes/backup/0_download.py  # ModelScope 模型下载
├── 2_Agent/OpenManus/            # Agent 框架
├── 2_Agent/MyAgent/gradio_v3.py  # Gradio UI
├── 4_LORA/                       # LORA 微调代码 + 数据集格式
├── 5_RAG/                        # RAG 管线 (Chroma + bge)
└── 1_Make_My_Data/               # 数据处理工具
```
